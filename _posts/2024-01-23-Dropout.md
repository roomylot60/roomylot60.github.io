---
title: 
author: Patrick
date: 2024-01-23 13:18:00 +0900
tags: []
categories: []
render_with_liquid: false
---
## Drop-out
### Drop-out
- Layer 간의 연결 관계에서 0~1 사이의 확률로 뉴런을 drop(제거)하는 기법
![](Attatched/Pasted%20image%2020240123120402.png)
- Drop-out rate = 0.5
- 4개의 뉴런끼리 모두 연결되어 있는 Fully-Connected Layer에서 각 뉴런은 0.5의 확률로 제거 여부가 랜덤으로 결정
- 실제로 4개에서 2개의 뉴런이 제거됨
### 사용 목적
- 특정 설명 변수 Feature에 Overfitting(과적합)된 학습을 방지하기 위해
- Drop-out을 적용하지 않고 모델을 학습하면 특정 Feature에 가중치가 가장 크게 설정되어 나머지 Feature들에 대해서는 학습이 이루어지지 않을 수 있음
- 따라서 일부 뉴런을 제거함으로써 특정 Feature에 대한 집중되지 않은 데이터를 얻고 이를 통해 과적합을 방지
### Ref.
[Drop-out](https://heytech.tistory.com/127)