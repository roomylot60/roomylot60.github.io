<!doctype html>














<!-- `site.alt_lang` can specify a language different from the UI -->
<html lang="ko" >
  <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e">
  <meta name="mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta
    name="viewport"
    content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover"
  >
  <!-- MathJax 추가 -->
  <script type="text/javascript" async
  src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script type="text/javascript" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><!-- Setup Open Graph image -->

  

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="DL in Netural Language Processing" />
<meta name="author" content="Patrick" />
<meta property="og:locale" content="ko" />
<meta name="description" content="Deep Learning Artificial Neural Network(인공 신경망)의 층을 연속적으로 쌓아올려 데이터를 학습 기계가 가중치를 스스로 찾아내도록 자동화 시키는 심층 신경망의 학습" />
<meta property="og:description" content="Deep Learning Artificial Neural Network(인공 신경망)의 층을 연속적으로 쌓아올려 데이터를 학습 기계가 가중치를 스스로 찾아내도록 자동화 시키는 심층 신경망의 학습" />
<link rel="canonical" href="http://localhost:4000/posts/DL_in_NLP/" />
<meta property="og:url" content="http://localhost:4000/posts/DL_in_NLP/" />
<meta property="og:site_name" content="Patrick’s Dev. Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-11-02T14:27:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="DL in Netural Language Processing" />
<meta name="twitter:site" content="@twitter_username" />
<meta name="twitter:creator" content="@Patrick" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Patrick"},"dateModified":"2023-11-02T14:27:00+09:00","datePublished":"2023-11-02T14:27:00+09:00","description":"Deep Learning Artificial Neural Network(인공 신경망)의 층을 연속적으로 쌓아올려 데이터를 학습 기계가 가중치를 스스로 찾아내도록 자동화 시키는 심층 신경망의 학습","headline":"DL in Netural Language Processing","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/posts/DL_in_NLP/"},"url":"http://localhost:4000/posts/DL_in_NLP/"}</script>
<!-- End Jekyll SEO tag -->


  <title>DL in Netural Language Processing | Patrick's Dev. Blog
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://realfavicongenerator.net/
-->



<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">

  <link rel="manifest" href="/assets/img/favicons/site.webmanifest">

<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="Patrick's Dev. Blog">
<meta name="application-name" content="Patrick's Dev. Blog">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">


  <!-- Resource Hints -->
  
    
      
        <link rel="preconnect" href="https://fonts.googleapis.com" >
      
        <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
      
    
      
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      
        <link rel="dns-prefetch" href="https://fonts.gstatic.com" >
      
    
      
        <link rel="preconnect" href="https://cdn.jsdelivr.net" >
      
        <link rel="dns-prefetch" href="https://cdn.jsdelivr.net" >
      
    
  

  <!-- Bootstrap -->
  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css">
  

  <!-- Theme style -->
  <link rel="stylesheet" href="/assets/css/jekyll-theme-chirpy.css">

  <!-- Web Font -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400&family=Source+Sans+Pro:wght@400;600;700;900&display=swap">

  <!-- Font Awesome Icons -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.1/css/all.min.css">

  <!-- 3rd-party Dependencies -->

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.32.2/dist/tocbot.min.css">
  

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.min.css">
  

  
    <!-- Image Popup -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/glightbox@3.3.0/dist/css/glightbox.min.css">
  

  <!-- Scripts -->

  <script src="/assets/js/dist/theme.min.js"></script>

  <!-- JS selector for site. -->

<!-- commons -->



<!-- layout specified -->


  

  
    <!-- image lazy-loading & popup & clipboard -->
    
  















  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  



  <script defer src="https://cdn.jsdelivr.net/combine/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.umd.min.js,npm/glightbox@3.3.0/dist/js/glightbox.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.13/dayjs.min.js,npm/dayjs@1.11.13/locale/en.js,npm/dayjs@1.11.13/plugin/relativeTime.js,npm/dayjs@1.11.13/plugin/localizedFormat.js,npm/tocbot@4.32.2/dist/tocbot.min.js"></script>







<script defer src="/assets/js/dist/post.min.js"></script>



<!-- Pageviews -->

  

  



  

  <!-- A placeholder to allow defining custom metadata -->

</head>


  <body>
    <!-- The Side Bar -->

<aside aria-label="Sidebar" id="sidebar" class="d-flex flex-column align-items-end">
  <header class="profile-wrapper">
    <a href="/" id="avatar" class="rounded-circle"><img src="https://chirpy-img.netlify.app/assets/img/profile.jpg" width="112" height="112" alt="avatar" onerror="this.style.display='none'"></a>

    <a class="site-title d-block" href="/">Patrick's Dev. Blog</a>
    <p class="site-subtitle fst-italic mb-0">이것 저것 해보는 중입니다</p>
  </header>
  <!-- .profile-wrapper -->

  <nav class="flex-column flex-grow-1 w-100 ps-0">
    <ul class="nav">
      <!-- home -->
      <li class="nav-item">
        <a href="/" class="nav-link">
          <i class="fa-fw fas fa-home"></i>
          <span>HOME</span>
        </a>
      </li>
      <!-- the real tabs -->
      
        <li class="nav-item">
          <a href="/categories/" class="nav-link">
            <i class="fa-fw fas fa-stream"></i>
            

            <span>CATEGORIES</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/tags/" class="nav-link">
            <i class="fa-fw fas fa-tags"></i>
            

            <span>TAGS</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/archives/" class="nav-link">
            <i class="fa-fw fas fa-archive"></i>
            

            <span>ARCHIVES</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/about/" class="nav-link">
            <i class="fa-fw fas fa-info-circle"></i>
            

            <span>ABOUT</span>
          </a>
        </li>
        <!-- .nav-item -->
      
    </ul>
  </nav>

  <div class="sidebar-bottom d-flex flex-wrap  align-items-center w-100">
    
      <button type="button" class="btn btn-link nav-link" aria-label="Switch Mode" id="mode-toggle">
        <i class="fas fa-adjust"></i>
      </button>

      
        <span class="icon-border"></span>
      
    

    
      

      
        <a
          href="https://github.com/roomylot60"
          aria-label="github"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fab fa-github"></i>
        </a>
      
    
      

      
        <a
          href="https://twitter.com/twitter_username"
          aria-label="twitter"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fa-brands fa-x-twitter"></i>
        </a>
      
    
      

      
        <a
          href="javascript:location.href = 'mailto:' + ['min2max.dev','google.com'].join('@')"
          aria-label="email"
          

          

          

          
        >
          <i class="fas fa-envelope"></i>
        </a>
      
    
      

      
        <a
          href="/feed.xml"
          aria-label="rss"
          

          

          

          
        >
          <i class="fas fa-rss"></i>
        </a>
      
    
  </div>
  <!-- .sidebar-bottom -->
</aside>
<!-- #sidebar -->


    <div id="main-wrapper" class="d-flex justify-content-center">
      <div class="container d-flex flex-column px-xxl-5">
        <!-- The Top Bar -->

<header id="topbar-wrapper" aria-label="Top Bar">
  <div
    id="topbar"
    class="d-flex align-items-center justify-content-between px-lg-3 h-100"
  >
    <nav id="breadcrumb" aria-label="Breadcrumb">
      

      
        
          
            <span>
              <a href="/">Home</a>
            </span>

          
        
          
        
          
            
              <span>DL in Netural Language Processing</span>
            

          
        
      
    </nav>
    <!-- endof #breadcrumb -->

    <button type="button" id="sidebar-trigger" class="btn btn-link" aria-label="Sidebar">
      <i class="fas fa-bars fa-fw"></i>
    </button>

    <div id="topbar-title">
      Post
    </div>

    <button type="button" id="search-trigger" class="btn btn-link" aria-label="Search">
      <i class="fas fa-search fa-fw"></i>
    </button>

    <search id="search" class="align-items-center ms-3 ms-lg-0">
      <i class="fas fa-search fa-fw"></i>
      <input
        class="form-control"
        id="search-input"
        type="search"
        aria-label="search"
        autocomplete="off"
        placeholder="Search..."
      >
    </search>
    <button type="button" class="btn btn-link text-decoration-none" id="search-cancel">Cancel</button>
  </div>
</header>


        <div class="row flex-grow-1">
          <main aria-label="Main Content" class="col-12 col-lg-11 col-xl-9 px-md-4">
            
              <!-- Refactor the HTML structure -->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->



<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->



<!-- Change the icon of checkbox -->



<!-- Handle images -->





<!-- Add header for code snippets -->



<!-- Create heading anchors -->





  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    

    
  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    

    
  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    

    
  

  
  

  




<!-- return -->










<article class="px-1" data-toc="true">
  <header>
    <h1 data-toc-skip>DL in Netural Language Processing</h1>
    

    <div class="post-meta text-muted">
      <!-- published date -->
      <span>
        Posted
        <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1698902820"
  data-df="ll"
  
    data-bs-toggle="tooltip" data-bs-placement="bottom"
  
>
  Nov  2, 2023
</time>

      </span>

      <!-- lastmod date -->
      

      

      <div class="d-flex justify-content-between">
        <!-- author(s) -->
        <span>
          

          By

          <em>
            
              
                
                
              
            
          </em>
        </span>

        <div>
          <!-- pageviews -->
          

          <!-- read time -->
          <!-- Calculate the post's reading time, and display the word count in tooltip -->



<!-- words per minute -->










<!-- return element -->
<span
  class="readtime"
  data-bs-toggle="tooltip"
  data-bs-placement="bottom"
  title="2461 words"
>
  <em>13 min</em> read</span>

        </div>
      </div>
    </div>
  </header>

  
    <div id="toc-bar" class="d-flex align-items-center justify-content-between invisible">
      <span class="label text-truncate">DL in Netural Language Processing</span>
      <button type="button" class="toc-trigger btn me-1">
        <i class="fa-solid fa-list-ul fa-fw"></i>
      </button>
    </div>

    <button id="toc-solo-trigger" type="button" class="toc-trigger btn btn-outline-secondary btn-sm">
      <span class="label ps-2 pe-1">Contents</span>
      <i class="fa-solid fa-angle-right fa-fw"></i>
    </button>

    <dialog id="toc-popup" class="p-0">
      <div class="header d-flex flex-row align-items-center justify-content-between">
        <div class="label text-truncate py-2 ms-4">DL in Netural Language Processing</div>
        <button id="toc-popup-close" type="button" class="btn mx-1 my-1 opacity-75">
          <i class="fas fa-close"></i>
        </button>
      </div>
      <div id="toc-popup-content" class="px-4 py-3 pb-4"></div>
    </dialog>
  

  <div class="content">
    <h2 id="deep-learning"><span class="me-2">Deep Learning</span><a href="#deep-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<ul>
  <li>Artificial Neural Network(인공 신경망)의 층을 연속적으로 쌓아올려 데이터를 학습</li>
  <li>기계가 가중치를 스스로 찾아내도록 자동화 시키는 심층 신경망의 학습</li>
</ul>

<h3 id="perceptron퍼셉트론"><span class="me-2">Perceptron(퍼셉트론)</span><a href="#perceptron퍼셉트론" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li>초기 형태의 인공 신경망</li>
  <li>입력값 x 벡터에 대해 가중치 w를 곱하고 편향 b(-임계값)을 더해 결과값 y를 도출</li>
</ul>

<h4 id="single-layer-perceptron"><span class="me-2">Single-Layer Perceptron</span><a href="#single-layer-perceptron" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
<ul>
  <li>Input layer(입력층)과 Output layer(출력층)으로 구성</li>
</ul>

<h4 id="multi-layer-perceptron"><span class="me-2">Multi-Layer Perceptron</span><a href="#multi-layer-perceptron" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
<ul>
  <li>Input, Output layer 사이에 Hidden layer(은닉층)을 두어 좀 더 복잡한 문제에 대응</li>
</ul>

<h3 id="forward-propagation순전파"><span class="me-2">Forward Propagation(순전파)</span><a href="#forward-propagation순전파" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li>입력층에서 출력층 방향으로 연산을 진행하는 과정</li>
</ul>

<h3 id="backpropagation역전파"><span class="me-2">BackPropagation(역전파)</span><a href="#backpropagation역전파" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li>순전파 과정을 진행하여 예측값과 실제값의 오차를 계산하였을 때, 경사 하강법을 사용하여 학습률을 반영해 가중치를 업데이트하는 과정</li>
</ul>

<h3 id="conception"><span class="me-2">Conception</span><a href="#conception" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<h4 id="loss-function"><span class="me-2">Loss function</span><a href="#loss-function" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
<ul>
  <li>실제값과 예측값의 차이를 수치화 해주는 함수</li>
</ul>

<div class="table-wrapper"><table>
  <thead>
    <tr>
      <th>Loss function</th>
      <th>Descriptions</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Mean Square Eval</td>
      <td>sample</td>
    </tr>
    <tr>
      <td>Binary Cross-Entropy</td>
      <td>sample</td>
    </tr>
    <tr>
      <td>Categorical Cross-Entropy</td>
      <td>sample</td>
    </tr>
  </tbody>
</table></div>

<h4 id="batch"><span class="me-2">Batch</span><a href="#batch" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
<ul>
  <li>가중치 등의 매개 변수의 값을 조정하기 위해 사용하는 데이터의 양</li>
  <li>Batch Gradient Descent : Optimizer 중 하나로 오차를 구할 때 전체 데이터를 고려</li>
  <li>Stochastic GD : 랜덤으로 선택한 하나의 데이터에 대해서만 경사 하강법을 계산</li>
  <li>Mini-Batch GD : 적당한 수의 배치 크기를 지정하여 GD를 실행</li>
</ul>

<h4 id="optimizer"><span class="me-2">Optimizer</span><a href="#optimizer" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
<ul>
  <li>Compile 과정에서 사용</li>
</ul>

<div class="table-wrapper"><table>
  <thead>
    <tr>
      <th>Optimizer</th>
      <th>Descriptions</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Momentum</td>
      <td>GD에서 계산된 접선의 기울기에 한 시점 전의 접선의 기울기 값을 일정한 비율만큼 반영</td>
    </tr>
    <tr>
      <td>Adagrad</td>
      <td>각각의 매개변수에 서로 다른 학습률을 적용</td>
    </tr>
    <tr>
      <td>RMSprop</td>
      <td>Adagrad의 학습률이 지나치게 떨어지는 단점을 보완하기 위해 사용</td>
    </tr>
    <tr>
      <td><strong>Adam</strong></td>
      <td>RMSprop과 Momentum을 합친 방식</td>
    </tr>
  </tbody>
</table></div>

<h4 id="epoch"><span class="me-2">Epoch</span><a href="#epoch" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
<ul>
  <li>인공 신경망에서 전체 데이터에 대해서 순전파와 역전파가 끝난 상태로 훈련 및 검증 과정이 한차례 끝난 것</li>
</ul>

<h3 id="gradient"><span class="me-2">Gradient</span><a href="#gradient" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<h4 id="problems"><span class="me-2">Problems</span><a href="#problems" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
<ul>
  <li>Gradient Vanishing : 역전파 과정에서 입력층으로 갈 수록 기울기가 점차적으로 작아져 입력층에 가까운 층들에서의 업데이트가 제대로 이루어지지 않는 상태</li>
  <li>Gradient Exploding : 기울기가 점차 커져서 가중치들의 값이 발산</li>
</ul>

<h4 id="resolutions"><span class="me-2">Resolutions</span><a href="#resolutions" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
<ol>
  <li>
    <p>Gradient Clipping : 기울기 폭주를 막기 위해 임계값을 넘지 않도록 값을 제한</p>
  </li>
  <li>
    <p>Weight initialization(가중치 초기화)</p>
    <ul>
      <li>Xavier Initialization : 이전 층과 다음 층의 뉴런의 개수를 고려하여, 여러 층의 기울기 분산 사이에 균형을 맞춰서 특정 층이 너무 주목을 받거나 다른 층이 뒤쳐지는 것을 방지(S자 형태의 activation function에서 좋은 성능)</li>
    </ul>
  </li>
</ol>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/nlp/Xavier_uniform.jpg" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/nlp/Xavier_normal.jpg" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

<ul>
  <li>He Initialization : 이전 층의 뉴런의 개수를 반영하여 초기화(ReLU 계열 함수에 효율적)</li>
</ul>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/nlp/He_uniform.jpg" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/nlp/He_normal.jpg" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

<ol>
  <li>Batch Normalization(배치 정규화) : 인공 신경망에 들어가는 각 입력을 평균과 분산으로 정규화
    <ul>
      <li>Internal Covariate Shift(내부 공변량 변화) : 학습에 의해 가중치가 변화하면, 입력 시점에 따라 입력 데이터의 분포가 변화하는 것</li>
    </ul>
  </li>
  <li>Layer Normalization(층 정규화)</li>
</ol>

<h3 id="과적합을-방지하는-방법"><span class="me-2">과적합을 방지하는 방법</span><a href="#과적합을-방지하는-방법" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ol>
  <li>
    <p>데이터의 양을 늘리기 : 데이터의 양이 적을 때, 데이터의 특정 패턴이나 노이즈까지 쉽게 암기할 수 있으므로, 데이터의 양을 늘려 일반적인 패턴을 학습(ex - Data Augmentation, Back Translation)</p>
  </li>
  <li>
    <p>모델의 복잡도 줄이기 : 은닉층의 수, 매개변수의 수를 줄여서 사용</p>
  </li>
  <li>Regularization(가중치 규제) 적용하기
    <ul>
      <li>L1 regularization : 가중치 w들의 절댓값의 합을 비용함수에 추가</li>
      <li>L2 regularization : 모든 가중치 w들의 제곱합을 비용함수에 추가</li>
    </ul>
  </li>
  <li>Dropout : 학습 과정에서 설정한 비율로 랜덤한 신경망을 사용하지 않는 방법으로, 특정 뉴런 또는 특정 조합에 너무 의존적으로 되는 것을 방지</li>
</ol>

<hr />

<h2 id="keras"><span class="me-2">Keras</span><a href="#keras" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="preprocessing"><span class="me-2">Preprocessing</span><a href="#preprocessing" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li>Tokenizer() : 토큰화, 정수 인코딩을 통해 단어 집합 생성</li>
</ul>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><span class="kn">from</span> <span class="n">tensorflow.keras.preprocessing.text</span> <span class="kn">import</span> <span class="n">Tokenizer</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="nc">Tokenizer</span><span class="p">()</span>
<span class="n">train_text</span> <span class="o">=</span> <span class="sh">"</span><span class="s">The earth is an awesome place live</span><span class="sh">"</span>

<span class="c1"># Vocabulary dictionary
</span><span class="n">tokenizer</span><span class="p">.</span><span class="nf">fit_on_texts</span><span class="p">([</span><span class="n">train_text</span><span class="p">])</span>

<span class="c1"># Index encoding
</span><span class="n">sub_text</span> <span class="o">=</span> <span class="sh">"</span><span class="s">The earth is an great place live</span><span class="sh">"</span>
<span class="n">sequences</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="nf">texts_to_sequences</span><span class="p">([</span><span class="n">sub_text</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Encoding : </span><span class="sh">"</span><span class="p">,</span> <span class="n">sequences</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Vocabulary Set : </span><span class="sh">"</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">word_index</span><span class="p">)</span>
</code></div></div>

<div class="language-bash highlighter-rouge"><div class="code-header">
        <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code>정수 인코딩 :  <span class="o">[</span>1, 2, 3, 4, 6, 7]
단어 집합 :  <span class="o">{</span><span class="s1">'the'</span>: 1, <span class="s1">'earth'</span>: 2, <span class="s1">'is'</span>: 3, <span class="s1">'an'</span>: 4, <span class="s1">'awesome'</span>: 5, <span class="s1">'place'</span>: 6, <span class="s1">'live'</span>: 7<span class="o">}</span>
</code></div></div>

<ul>
  <li>texts_to_matrix() : 입력된 텍스트 데이터를 행렬로 변환
    <ul>
      <li>binary : 해당 단어의 존재 여부</li>
      <li>count : DTM 생성</li>
      <li>freq : 각 문서에서 각 단어의 등장 횟수 / 각 문서의 모든 단어의 개수</li>
      <li>tfidf : TF-IDF 행렬 생성</li>
    </ul>
  </li>
  <li>pad_sequences() : 샘플의 길이가 서로 다를 때, padding을 거쳐 필요한 부분을 0으로, 필요없는 부분은 제거하여 동일하게 맞춤</li>
</ul>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><span class="kn">from</span> <span class="n">tensorflow.keras.preprocessing.sequence</span> <span class="kn">import</span> <span class="n">pad_sequence</span>

<span class="nf">print</span><span class="p">(</span><span class="nf">pad_sequences</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">],[</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">]],</span> <span class="n">maxlen</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="sh">'</span><span class="s">pre</span><span class="sh">'</span><span class="p">))</span>
</code></div></div>

<div class="language-bash highlighter-rouge"><div class="code-header">
        <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><span class="o">[[</span>1 2 3]
<span class="o">[</span>4 5 6]
<span class="o">[</span>0 7 8]]
</code></div></div>

<ul>
  <li>Word Embedding : 텍스트 내의 단어들을 dense vector로 변환하는 것으로, 학습을 통해 값이 변화
    <ul>
      <li>Embedding(vocab_size, embedding_dim, input_length) : 단어를 밀집 벡터로 변환(embedding layer 생성)</li>
    </ul>
  </li>
</ul>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/nlp/one_hot_vs_w_embedding.jpg" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

<ul>
  <li>Modeling
    <ul>
      <li>Sequential() : 모델에서 사용할 layer 생성을 위한 선언</li>
      <li>Dense(output_dim, input_dim, activation_function) : layer 추가 시, 해당 layer의 정보</li>
      <li>summary() : 모델의 정보를 요약</li>
    </ul>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><span class="kn">from</span> <span class="n">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Embedding</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span> <span class="c1"># Adding embedding layer
</span><span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">))</span> <span class="c1"># Adding fully-connected layer
</span><span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">sigmmoid</span><span class="sh">'</span><span class="p">))</span> <span class="c1"># Adding output layer pass 2nd parameter as you declared pre-layer output_dim,  5.
</span></code></div></div>

<ul>
  <li>Compile &amp; Training
    <ul>
      <li>compile(optimizer, loss, metrics) : 모델을 기계가 이해할 수 있도록 loss_function, optimizer, matric_function(평가 지표 함수)의 정보와 함께 compile</li>
      <li>fit(train_data, label_data, epochs, batch_size, (validation_data,) verbose, validation_split) : 모델의 학습을 진행
        <ul>
          <li>validation_data(x_val, y_val) : 검증 데이터를 활용</li>
          <li>validation_split : 훈련 데이터의 일정 비율을 검증 데이터로 활용</li>
          <li>verbose : 1일 때, 훈련의 진행도를 나타내는 진행 막대 표시, 2일 때, 미니 배치마다 손실 정보를 출력</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><span class="kn">from</span> <span class="n">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">SimpleRNN</span><span class="p">,</span> <span class="n">Embedding</span><span class="p">,</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="n">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>

<span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">hidden_units</span><span class="o">=</span> <span class="mi">32</span>

<span class="c1"># Declare Model
</span><span class="n">model</span> <span class="o">=</span> <span class="nc">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">SimpleRNN</span><span class="p">(</span><span class="n">hidden_units</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">sigmoid</span><span class="sh">'</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="sh">'</span><span class="s">rmsprop</span><span class="sh">'</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="sh">'</span><span class="s">binary_crossentropy</span><span class="sh">'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">acc</span><span class="sh">'</span><span class="p">])</span>

<span class="c1"># Training
</span><span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="c1"># Evaluation
</span><span class="n">model</span><span class="p">.</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

<span class="c1"># Prediction
</span><span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_input</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

<span class="c1"># Save
</span><span class="n">model</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="sh">"</span><span class="s">model_name.h5</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Load
</span><span class="kn">from</span> <span class="n">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>
<span class="n">model2</span> <span class="o">=</span> <span class="nf">load_model</span><span class="p">(</span><span class="sh">"</span><span class="s">model_name.h5</span><span class="sh">"</span><span class="p">)</span>
</code></div></div>

<ul>
  <li>Evaluation &amp; Prediction
    <ul>
      <li>evaluate(test_data, test_label, batch_size)</li>
      <li>predict(data, batch_size)</li>
    </ul>
  </li>
  <li>Save &amp; Load
    <ul>
      <li>save(“model_path + model_name”) : hdf5 file로 저장</li>
      <li>load_model(“model_path + model_name”) : 저장 된 모델 로드</li>
    </ul>
  </li>
</ul>

<h3 id="functional-api"><span class="me-2">Functional API</span><a href="#functional-api" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li>Layer 생성에 있어서 각 층을 일종의 함수로서 정의하고 연산자를 통해 신경망을 설계</li>
</ul>

<h4 id="ffnn"><span class="me-2">FFNN</span><a href="#ffnn" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><span class="kn">from</span> <span class="n">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="n">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Model</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span> <span class="c1"># 10개의 입력을 받는 입력층
</span><span class="n">hidden1</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">hidden2</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)(</span><span class="n">hidden1</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">sigmoid</span><span class="sh">'</span><span class="p">)(</span><span class="n">hidden2</span><span class="p">)</span> <span class="c1"># input-&gt;hidden1-&gt;hidden2-&gt;ouptut 으로 구성
</span>
<span class="c1"># 모델 생성 및 학습 진행
</span><span class="n">model</span> <span class="o">=</span> <span class="nc">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">ouputs</span><span class="o">=</span><span class="n">output</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="sh">'</span><span class="s">rmsprop</span><span class="sh">'</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="sh">'</span><span class="s">categorical_crossentropy</span><span class="sh">'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">acc</span><span class="sh">'</span><span class="p">])</span>
<span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</code></div></div>

<h4 id="linear-regression"><span class="me-2">Linear Regression</span><a href="#linear-regression" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><span class="kn">from</span> <span class="n">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="n">tensorflow.keras</span> <span class="kn">import</span> <span class="n">optimizers</span>
<span class="kn">from</span> <span class="n">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Model</span>

<span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]</span> <span class="c1"># 공부하는 시간
</span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">44</span><span class="p">,</span> <span class="mi">53</span><span class="p">,</span> <span class="mi">66</span><span class="p">,</span> <span class="mi">77</span><span class="p">,</span> <span class="mi">87</span><span class="p">,</span> <span class="mi">95</span><span class="p">]</span> <span class="c1"># 각 공부하는 시간에 맵핑되는 성적
</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,))</span>
<span class="n">output</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">linear</span><span class="sh">'</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">linear_model</span> <span class="o">=</span> <span class="nc">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>

<span class="n">sgd</span> <span class="o">=</span> <span class="n">optimizers</span><span class="p">.</span><span class="nc">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="n">linear_model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">sgd</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="sh">'</span><span class="s">mse</span><span class="sh">'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">mse</span><span class="sh">'</span><span class="p">])</span>
<span class="n">linear_model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
</code></div></div>

<h4 id="logistic-regression"><span class="me-2">Logistic Regression</span><a href="#logistic-regression" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><span class="kn">from</span> <span class="n">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="n">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Model</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,))</span>
<span class="n">output</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">sigmoid</span><span class="sh">'</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">logistic_model</span> <span class="o">=</span> <span class="nc">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
</code></div></div>
<ul>
  <li>RNN;Recurrence Neural Network -&gt; 은닉층 생성</li>
</ul>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><span class="kn">from</span> <span class="n">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">LSTM</span>
<span class="kn">from</span> <span class="n">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Model</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="nc">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">lstm_layer</span> <span class="o">=</span> <span class="nc">LSTM</span><span class="p">(</span><span class="mi">10</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)(</span><span class="n">lstm_layer</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="nc">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">sigmoid</span><span class="sh">'</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">output</span><span class="p">)</span>
</code></div></div>

<h3 id="sub-classing-api"><span class="me-2">Sub-Classing API</span><a href="#sub-classing-api" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<h4 id="linear-regression-1"><span class="me-2">Linear Regression</span><a href="#linear-regression-1" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="c1"># 선형 회귀에 대한 class 정의
</span><span class="k">class</span> <span class="nc">LinearRegression</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="c1"># 모델의 구조 및 동작을 정의하는 생성자 정의
</span>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">LinearRegression</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">linear_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">linear</span><span class="sh">'</span><span class="p">)</span>

    <span class="c1"># 데이터를 입력 받아 예측값을 리턴하는 forward 연산
</span>    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">linear_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y_pred</span>

<span class="c1"># 모델 생성
</span><span class="n">model</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">()</span>

<span class="c1"># 데이터
</span><span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]</span> <span class="c1"># 공부하는 시간
</span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">22</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">44</span><span class="p">,</span> <span class="mi">53</span><span class="p">,</span> <span class="mi">66</span><span class="p">,</span> <span class="mi">77</span><span class="p">,</span> <span class="mi">87</span><span class="p">,</span> <span class="mi">95</span><span class="p">]</span> <span class="c1"># 각 공부하는 시간에 맵핑되는 성적
</span>
<span class="n">sgd</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">sgd</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="sh">'</span><span class="s">mse</span><span class="sh">'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">mse</span><span class="sh">'</span><span class="p">])</span>
<span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
</code></div></div>

<hr />

<h2 id="neural-network-language-modelnnlm신경망-언어-모델"><span class="me-2">Neural Network Language Model;NNLM(신경망 언어 모델)</span><a href="#neural-network-language-modelnnlm신경망-언어-모델" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="nnlm"><span class="me-2">NNLM</span><a href="#nnlm" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li>자연어 학습에 대해 과거의 통계적인 접근방식(SLM)이 아닌, 인공 신경망을 사용하는 방식으로(ex - FFNNLM, RNNLM, BiLM)
    <ul>
      <li>앞의 모든 단어를 참고하는 것이 아니라 정해진 개수의 단어(window)만을 참고하여 해당 window의 one-hot vector를 생성</li>
      <li>입력된 one-hot vector들을 은닉층 중 활성화 함수가 존재하지 않는 투사층(projection layer)에서 가중치 행렬과 곱하여 lookup table을 생성</li>
      <li>Lookup table의 값은 최초에는 랜덤한 값을 가지지만 학습을 거치면서 값이 변경</li>
      <li>테이블의 각각의 값, Embedding vector는 은닉층을 거쳐 활성화 함수를 통해 window의 크기;<code class="language-plaintext highlighter-rouge">V</code>와 같은 차원의 벡터를 출력</li>
      <li>출력층에서 활성화 함수(softmax)를 거쳐 0~1 사이의 값을 갖고 총 합이 1인 <code class="language-plaintext highlighter-rouge">V</code>차원의 벡터를 손실함수로 cross-entropy를 사용해 예측값을 결정</li>
    </ul>
  </li>
</ul>

<h3 id="n-gram-lm"><span class="me-2">N-gram LM</span><a href="#n-gram-lm" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li>Language Model : 문장에 확률을 할당하는 모델</li>
  <li>Language Modeling : 주어진 문맥으로부터 모르는 단어를 예측하는 것</li>
  <li>N-gram LM : 바로 앞의 <code class="language-plaintext highlighter-rouge">n-1</code>개의 단어를 참고하여 <code class="language-plaintext highlighter-rouge">n</code>번째 단어를 예측하는 모델</li>
</ul>

<h3 id="recurrent-neural-network-rnn"><span class="me-2">Recurrent Neural Network; RNN</span><a href="#recurrent-neural-network-rnn" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li>RNN : 입력과 출력을 sequence(묶음) 단위로 처리하는 모델</li>
</ul>

<h3 id="long-short-term-memorylstm"><span class="me-2">Long Short-Term Memory;LSTM</span><a href="#long-short-term-memorylstm" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li>LSTM : 은닉층의 메모리 셀에 입력 게이트, 망각 게이트, 출력 게이트를 추가하여 불필요한 기억은 지우고, 기억해야할 것들을 선정</li>
</ul>

  </div>

  <div class="post-tail-wrapper text-muted">
    <!-- categories -->
    
      <div class="post-meta mb-3">
        <i class="far fa-folder-open fa-fw me-1"></i>
        
          <a href="/categories/nlp/">NLP</a>
      </div>
    

    <!-- tags -->
    
      <div class="post-tags">
        <i class="fa fa-tags fa-fw me-1"></i>
        
          <a
            href="/tags/concept/"
            class="post-tag no-text-decoration"
          >Concept</a>
        
      </div>
    

    <div
      class="
        post-tail-bottom
        d-flex justify-content-between align-items-center mt-5 pb-2
      "
    >
      <div class="license-wrapper">
        
          

          This post is licensed under 
        <a href="https://creativecommons.org/licenses/by/4.0/">
          CC BY 4.0
        </a>
         by the author.
        
      </div>

      <!-- Post sharing snippet -->

<div class="share-wrapper d-flex align-items-center">
  <span class="share-label text-muted">Share</span>
  <span class="share-icons">
    
    
    

    

      

      <a href="https://twitter.com/intent/tweet?text=DL%20in%20Netural%20Language%20Processing%20-%20Patrick's%20Dev.%20Blog&url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2FDL_in_NLP%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Twitter" aria-label="Twitter">
        <i class="fa-fw fa-brands fa-square-x-twitter"></i>
      </a>
    

      

      <a href="https://www.facebook.com/sharer/sharer.php?title=DL%20in%20Netural%20Language%20Processing%20-%20Patrick's%20Dev.%20Blog&u=http%3A%2F%2Flocalhost%3A4000%2Fposts%2FDL_in_NLP%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Facebook" aria-label="Facebook">
        <i class="fa-fw fab fa-facebook-square"></i>
      </a>
    

      

      <a href="https://t.me/share/url?url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2FDL_in_NLP%2F&text=DL%20in%20Netural%20Language%20Processing%20-%20Patrick's%20Dev.%20Blog" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Telegram" aria-label="Telegram">
        <i class="fa-fw fab fa-telegram"></i>
      </a>
    

    <button
      id="copy-link"
      aria-label="Copy link"
      class="btn small"
      data-bs-toggle="tooltip"
      data-bs-placement="top"
      title="Copy link"
      data-title-succeed="Link copied successfully!"
    >
      <i class="fa-fw fas fa-link pe-none fs-6"></i>
    </button>
  </span>
</div>

    </div>
    <!-- .post-tail-bottom -->
  </div>
  <!-- div.post-tail-wrapper -->
</article>


            
          </main>

          <!-- panel -->
          <aside aria-label="Panel" id="panel-wrapper" class="col-xl-3 ps-2 text-muted">
            <div class="access">
              <!-- Get 5 last posted/updated posts -->














  <section id="access-lastmod">
    <h2 class="panel-heading">Recently Updated</h2>
    <ul class="content list-unstyled ps-0 pb-1 ms-1 mt-2">
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/Graph/">Graph</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/pip_requiremntes/">Pip_requiremntes</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/BPE/">Bpe</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/Huggingface/">Huggingface</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/Datasets/">Datasets</a>
        </li>
      
    </ul>
  </section>
  <!-- #access-lastmod -->


              <!-- The trending tags list -->















  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        



  <section>
    <h2 class="panel-heading">Trending Tags</h2>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/concept/">Concept</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/grammer/">Grammer</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/bfs/">BFS</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/dfs/">DFS</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/graph/">Graph</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/paper/">Paper</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/tutorial/">Tutorial</a>
      
    </div>
  </section>


            </div>

            
              
              






  <div class="toc-border-cover z-3"></div>
  <section id="toc-wrapper" class="invisible position-sticky ps-0 pe-4 pb-4">
    <h2 class="panel-heading ps-3 pb-2 mb-0">Contents</h2>
    <nav id="toc"></nav>
  </section>


            
          </aside>
        </div>

        <div class="row">
          <!-- tail -->
          <div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-md-4">
            
              
              <!-- Recommend the other 3 posts according to the tags and categories of the current post. -->

<!-- The total size of related posts -->


<!-- An random integer that bigger than 0 -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy} -->















  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  
    
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  











  <aside id="related-posts" aria-labelledby="related-label">
    <h3 class="mb-4" id="related-label">Further Reading</h3>
    <nav class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4">
      
        <article class="col">
          <a href="/posts/Attention_Machanism/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1701774720"
  data-df="ll"
  
>
  Dec  5, 2023
</time>

              <h4 class="pt-0 my-2">Attention Algorithm</h4>
              <div class="text-muted">
                <p>Seq2seq based on RNN seq2seq Model : RNN에 기반하여 Encoder에서 입력 시퀀스를 context vector라는 하나의 고정된 크기의 벡터 표현으로 압축하고, Decoder에서 출력 시퀀스를 생성 문제점    하나의 고정된 크기의 벡터에 모든 정보를 압축; 정보 손실이 발생   RNN의 문제점 중 하나인 Vanishi...</p>
              </div>
            </div>
          </a>
        </article>
      
        <article class="col">
          <a href="/posts/Subword_Tokenizer/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1701168600"
  data-df="ll"
  
>
  Nov 28, 2023
</time>

              <h4 class="pt-0 my-2">Subword Tokenizer</h4>
              <div class="text-muted">
                <p>Subword Tokenizer Subword    OOV(Out-Of Vocabulary) : 새로 제시된 단어에 대해 기존의 dictionary 내의 단어가 아닌 경우   Subword : 하나의 단어를 구성하는 더 작은 단위의 의미를 가진 어구   Subword segmenation : 하나의 단어를 여러 서브 워드로 분리해서 단어를 인코딩 및 ...</p>
              </div>
            </div>
          </a>
        </article>
      
        <article class="col">
          <a href="/posts/LSTM/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1700556180"
  data-df="ll"
  
>
  Nov 21, 2023
</time>

              <h4 class="pt-0 my-2">Long Short-Term Memory in RNN</h4>
              <div class="text-muted">
                <p>Long Short-Term Memory; LSTM The problem of long-term dependencies    Vanila RNN(기본형 RNN)은 비교적 짧은 시퀀스에 대해서만 효과를 보임(시점이 길어질 수록 앞의 정보가 뒤로 충분히 전달되지 못하는 현상 발생)   LSTM    은닉층의 메모리 셀에 입력 게이트, 망각 게이트, 출력 ...</p>
              </div>
            </div>
          </a>
        </article>
      
    </nav>
  </aside>
  <!-- #related-posts -->


            
              
              <!-- Navigation buttons at the bottom of the post. -->

<nav class="post-navigation d-flex justify-content-between" aria-label="Post Navigation">
  
  

  
    <a
      href="/posts/ML_in_NLP/"
      class="btn btn-outline-primary"
      aria-label="Older"
    >
      <p>ML in Netural Language Processing</p>
    </a>
  

  
    <a
      href="/posts/RNN/"
      class="btn btn-outline-primary"
      aria-label="Newer"
    >
      <p>Concept of Recurrent Neural Network</p>
    </a>
  
</nav>

            

            <!-- The Footer -->

<footer
  aria-label="Site Info"
  class="
    d-flex flex-column justify-content-center text-muted
    flex-lg-row justify-content-lg-between align-items-lg-center pb-lg-3
  "
>
  <p>©
    <time>2025</time>

    
      <a href="https://twitter.com/username">Patrick</a>.
    

    
      <span
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author."
      >Some rights reserved.</span>
    
  </p>

  <p>Using the <a
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="v7.2.4"
        href="https://github.com/cotes2020/jekyll-theme-chirpy"
        target="_blank"
        rel="noopener"
      >Chirpy</a> theme for <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>.
  </p>
</footer>

          </div>
        </div>

        <!-- The Search results -->

<div id="search-result-wrapper" class="d-flex justify-content-center d-none">
  <div class="col-11 content">
    <div id="search-hints">
      <!-- The trending tags list -->















  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        



  <section>
    <h2 class="panel-heading">Trending Tags</h2>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/concept/">Concept</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/grammer/">Grammer</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/bfs/">BFS</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/dfs/">DFS</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/graph/">Graph</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/paper/">Paper</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/tutorial/">Tutorial</a>
      
    </div>
  </section>


    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>

      </div>

      <aside aria-label="Scroll to Top">
        <button id="back-to-top" type="button" class="btn btn-lg btn-box-shadow">
          <i class="fas fa-angle-up"></i>
        </button>
      </aside>
    </div>

    <div id="mask" class="d-none position-fixed w-100 h-100 z-1"></div>

    
      <aside
  id="notification"
  class="toast"
  role="alert"
  aria-live="assertive"
  aria-atomic="true"
  data-bs-animation="true"
  data-bs-autohide="false"
>
  <div class="toast-header">
    <button
      type="button"
      class="btn-close ms-auto"
      data-bs-dismiss="toast"
      aria-label="Close"
    ></button>
  </div>
  <div class="toast-body text-center pt-0">
    <p class="px-2 mb-3">A new version of content is available.</p>
    <button type="button" class="btn btn-primary" aria-label="Update">
      Update
    </button>
  </div>
</aside>

    

    <!-- Embedded scripts -->

    
      
      <!-- The comments switcher -->


    

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script>
  
  document.addEventListener('DOMContentLoaded', () => {
    SimpleJekyllSearch({
      searchInput: document.getElementById('search-input'),
      resultsContainer: document.getElementById('search-results'),
      json: '/assets/js/data/search.json',
      searchResultTemplate: '  <article class="px-1 px-sm-2 px-lg-4 px-xl-0">    <header>      <h2><a href="{url}">{title}</a></h2>      <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">        {categories}        {tags}      </div>    </header>    <p>{content}</p>  </article>',
      noResultsText: '<p class="mt-5">Oops! No results found.</p>',
      templateMiddleware: function(prop, value, template) {
        if (prop === 'categories') {
          if (value === '') {
            return `${value}`;
          } else {
            return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
          }
        }

        if (prop === 'tags') {
          if (value === '') {
            return `${value}`;
          } else {
            return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
          }
        }
      }
    });
  });
</script>

  </body>
</html>

