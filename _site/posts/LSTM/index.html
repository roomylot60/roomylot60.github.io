<!doctype html>














<!-- `site.alt_lang` can specify a language different from the UI -->
<html lang="ko" >
  <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e">
  <meta name="mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta
    name="viewport"
    content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover"
  >
  <!-- MathJax 추가 -->
  <script type="text/javascript" async
  src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script type="text/javascript" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><!-- Setup Open Graph image -->

  

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Long Short-Term Memory in RNN" />
<meta name="author" content="Patrick" />
<meta property="og:locale" content="ko" />
<meta name="description" content="Long Short-Term Memory; LSTM The problem of long-term dependencies Vanila RNN(기본형 RNN)은 비교적 짧은 시퀀스에 대해서만 효과를 보임(시점이 길어질 수록 앞의 정보가 뒤로 충분히 전달되지 못하는 현상 발생)" />
<meta property="og:description" content="Long Short-Term Memory; LSTM The problem of long-term dependencies Vanila RNN(기본형 RNN)은 비교적 짧은 시퀀스에 대해서만 효과를 보임(시점이 길어질 수록 앞의 정보가 뒤로 충분히 전달되지 못하는 현상 발생)" />
<link rel="canonical" href="http://localhost:4000/posts/LSTM/" />
<meta property="og:url" content="http://localhost:4000/posts/LSTM/" />
<meta property="og:site_name" content="Patrick’s Dev. Blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-11-21T17:43:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Long Short-Term Memory in RNN" />
<meta name="twitter:site" content="@twitter_username" />
<meta name="twitter:creator" content="@Patrick" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Patrick"},"dateModified":"2023-11-21T17:43:00+09:00","datePublished":"2023-11-21T17:43:00+09:00","description":"Long Short-Term Memory; LSTM The problem of long-term dependencies Vanila RNN(기본형 RNN)은 비교적 짧은 시퀀스에 대해서만 효과를 보임(시점이 길어질 수록 앞의 정보가 뒤로 충분히 전달되지 못하는 현상 발생)","headline":"Long Short-Term Memory in RNN","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/posts/LSTM/"},"url":"http://localhost:4000/posts/LSTM/"}</script>
<!-- End Jekyll SEO tag -->


  <title>Long Short-Term Memory in RNN | Patrick's Dev. Blog
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://realfavicongenerator.net/
-->



<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">

  <link rel="manifest" href="/assets/img/favicons/site.webmanifest">

<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="Patrick's Dev. Blog">
<meta name="application-name" content="Patrick's Dev. Blog">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">


  <!-- Resource Hints -->
  
    
      
        <link rel="preconnect" href="https://fonts.googleapis.com" >
      
        <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
      
    
      
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      
        <link rel="dns-prefetch" href="https://fonts.gstatic.com" >
      
    
      
        <link rel="preconnect" href="https://cdn.jsdelivr.net" >
      
        <link rel="dns-prefetch" href="https://cdn.jsdelivr.net" >
      
    
  

  <!-- Bootstrap -->
  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css">
  

  <!-- Theme style -->
  <link rel="stylesheet" href="/assets/css/jekyll-theme-chirpy.css">

  <!-- Web Font -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400&family=Source+Sans+Pro:wght@400;600;700;900&display=swap">

  <!-- Font Awesome Icons -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.1/css/all.min.css">

  <!-- 3rd-party Dependencies -->

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.32.2/dist/tocbot.min.css">
  

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.min.css">
  

  
    <!-- Image Popup -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/glightbox@3.3.0/dist/css/glightbox.min.css">
  

  <!-- Scripts -->

  <script src="/assets/js/dist/theme.min.js"></script>

  <!-- JS selector for site. -->

<!-- commons -->



<!-- layout specified -->


  

  
    <!-- image lazy-loading & popup & clipboard -->
    
  















  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  



  <script defer src="https://cdn.jsdelivr.net/combine/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.umd.min.js,npm/glightbox@3.3.0/dist/js/glightbox.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.13/dayjs.min.js,npm/dayjs@1.11.13/locale/en.js,npm/dayjs@1.11.13/plugin/relativeTime.js,npm/dayjs@1.11.13/plugin/localizedFormat.js,npm/tocbot@4.32.2/dist/tocbot.min.js"></script>







<script defer src="/assets/js/dist/post.min.js"></script>



<!-- Pageviews -->

  

  



  

  <!-- A placeholder to allow defining custom metadata -->

</head>


  <body>
    <!-- The Side Bar -->

<aside aria-label="Sidebar" id="sidebar" class="d-flex flex-column align-items-end">
  <header class="profile-wrapper">
    <a href="/" id="avatar" class="rounded-circle"><img src="https://chirpy-img.netlify.app/assets/img/profile.jpg" width="112" height="112" alt="avatar" onerror="this.style.display='none'"></a>

    <a class="site-title d-block" href="/">Patrick's Dev. Blog</a>
    <p class="site-subtitle fst-italic mb-0">이것 저것 해보는 중입니다</p>
  </header>
  <!-- .profile-wrapper -->

  <nav class="flex-column flex-grow-1 w-100 ps-0">
    <ul class="nav">
      <!-- home -->
      <li class="nav-item">
        <a href="/" class="nav-link">
          <i class="fa-fw fas fa-home"></i>
          <span>HOME</span>
        </a>
      </li>
      <!-- the real tabs -->
      
        <li class="nav-item">
          <a href="/categories/" class="nav-link">
            <i class="fa-fw fas fa-stream"></i>
            

            <span>CATEGORIES</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/tags/" class="nav-link">
            <i class="fa-fw fas fa-tags"></i>
            

            <span>TAGS</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/archives/" class="nav-link">
            <i class="fa-fw fas fa-archive"></i>
            

            <span>ARCHIVES</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/about/" class="nav-link">
            <i class="fa-fw fas fa-info-circle"></i>
            

            <span>ABOUT</span>
          </a>
        </li>
        <!-- .nav-item -->
      
    </ul>
  </nav>

  <div class="sidebar-bottom d-flex flex-wrap  align-items-center w-100">
    
      <button type="button" class="btn btn-link nav-link" aria-label="Switch Mode" id="mode-toggle">
        <i class="fas fa-adjust"></i>
      </button>

      
        <span class="icon-border"></span>
      
    

    
      

      
        <a
          href="https://github.com/roomylot60"
          aria-label="github"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fab fa-github"></i>
        </a>
      
    
      

      
        <a
          href="https://twitter.com/twitter_username"
          aria-label="twitter"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fa-brands fa-x-twitter"></i>
        </a>
      
    
      

      
        <a
          href="javascript:location.href = 'mailto:' + ['min2max.dev','google.com'].join('@')"
          aria-label="email"
          

          

          

          
        >
          <i class="fas fa-envelope"></i>
        </a>
      
    
      

      
        <a
          href="/feed.xml"
          aria-label="rss"
          

          

          

          
        >
          <i class="fas fa-rss"></i>
        </a>
      
    
  </div>
  <!-- .sidebar-bottom -->
</aside>
<!-- #sidebar -->


    <div id="main-wrapper" class="d-flex justify-content-center">
      <div class="container d-flex flex-column px-xxl-5">
        <!-- The Top Bar -->

<header id="topbar-wrapper" aria-label="Top Bar">
  <div
    id="topbar"
    class="d-flex align-items-center justify-content-between px-lg-3 h-100"
  >
    <nav id="breadcrumb" aria-label="Breadcrumb">
      

      
        
          
            <span>
              <a href="/">Home</a>
            </span>

          
        
          
        
          
            
              <span>Long Short-Term Memory in RNN</span>
            

          
        
      
    </nav>
    <!-- endof #breadcrumb -->

    <button type="button" id="sidebar-trigger" class="btn btn-link" aria-label="Sidebar">
      <i class="fas fa-bars fa-fw"></i>
    </button>

    <div id="topbar-title">
      Post
    </div>

    <button type="button" id="search-trigger" class="btn btn-link" aria-label="Search">
      <i class="fas fa-search fa-fw"></i>
    </button>

    <search id="search" class="align-items-center ms-3 ms-lg-0">
      <i class="fas fa-search fa-fw"></i>
      <input
        class="form-control"
        id="search-input"
        type="search"
        aria-label="search"
        autocomplete="off"
        placeholder="Search..."
      >
    </search>
    <button type="button" class="btn btn-link text-decoration-none" id="search-cancel">Cancel</button>
  </div>
</header>


        <div class="row flex-grow-1">
          <main aria-label="Main Content" class="col-12 col-lg-11 col-xl-9 px-md-4">
            
              <!-- Refactor the HTML structure -->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->



<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->



<!-- Change the icon of checkbox -->



<!-- Handle images -->





<!-- Add header for code snippets -->



<!-- Create heading anchors -->





  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      
    

    
  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    

    
  

  
  

  

  
  

  




<!-- return -->










<article class="px-1" data-toc="true">
  <header>
    <h1 data-toc-skip>Long Short-Term Memory in RNN</h1>
    

    <div class="post-meta text-muted">
      <!-- published date -->
      <span>
        Posted
        <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1700556180"
  data-df="ll"
  
    data-bs-toggle="tooltip" data-bs-placement="bottom"
  
>
  Nov 21, 2023
</time>

      </span>

      <!-- lastmod date -->
      

      

      <div class="d-flex justify-content-between">
        <!-- author(s) -->
        <span>
          

          By

          <em>
            
              
                
                
              
            
          </em>
        </span>

        <div>
          <!-- pageviews -->
          

          <!-- read time -->
          <!-- Calculate the post's reading time, and display the word count in tooltip -->



<!-- words per minute -->










<!-- return element -->
<span
  class="readtime"
  data-bs-toggle="tooltip"
  data-bs-placement="bottom"
  title="2742 words"
>
  <em>15 min</em> read</span>

        </div>
      </div>
    </div>
  </header>

  
    <div id="toc-bar" class="d-flex align-items-center justify-content-between invisible">
      <span class="label text-truncate">Long Short-Term Memory in RNN</span>
      <button type="button" class="toc-trigger btn me-1">
        <i class="fa-solid fa-list-ul fa-fw"></i>
      </button>
    </div>

    <button id="toc-solo-trigger" type="button" class="toc-trigger btn btn-outline-secondary btn-sm">
      <span class="label ps-2 pe-1">Contents</span>
      <i class="fa-solid fa-angle-right fa-fw"></i>
    </button>

    <dialog id="toc-popup" class="p-0">
      <div class="header d-flex flex-row align-items-center justify-content-between">
        <div class="label text-truncate py-2 ms-4">Long Short-Term Memory in RNN</div>
        <button id="toc-popup-close" type="button" class="btn mx-1 my-1 opacity-75">
          <i class="fas fa-close"></i>
        </button>
      </div>
      <div id="toc-popup-content" class="px-4 py-3 pb-4"></div>
    </dialog>
  

  <div class="content">
    <h2 id="long-short-term-memory-lstm"><span class="me-2">Long Short-Term Memory; LSTM</span><a href="#long-short-term-memory-lstm" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="the-problem-of-long-term-dependencies"><span class="me-2">The problem of long-term dependencies</span><a href="#the-problem-of-long-term-dependencies" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li>Vanila RNN(기본형 RNN)은 비교적 짧은 시퀀스에 대해서만 효과를 보임(시점이 길어질 수록 앞의 정보가 뒤로 충분히 전달되지 못하는 현상 발생)</li>
</ul>

<h3 id="lstm"><span class="me-2">LSTM</span><a href="#lstm" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li>은닉층의 메모리 셀에 입력 게이트, 망각 게이트, 출력 게이트를 추가하여 불필요한 기억은 지우고, 기억해야할 것들을 선정</li>
</ul>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/nlp/LSTM_architecture.jpg" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

<ul>
  <li>Cell state : 이전 시점의 셀 상태가 다음 시점의 셀 상태를 구하기 위한 입력으로 사용, 삭제 게이트의 값이 0에 가까울 수록 이전 시점의 셀 상태값의 영향력이 작아지고, 입력 게이트의 값이 현 시점의 셀 상태에 영향을 미침(<code class="language-plaintext highlighter-rouge">$$C_{t} = f_{t}ｏC_{t-1} + i_{t}ｏg_{t}$$</code>)
    <ul>
      <li>Entrywise product : 두 행렬에서 같은 위치의 성분끼리의 곱을 통해 얻어지는 행렬</li>
    </ul>
  </li>
  <li>입력 게이트 : 현재 정보를 기억하기 위한 게이트(<code class="language-plaintext highlighter-rouge">i_t = sigmoid(x_t*W_(xi) + h_(t-1)*W_(hi)), g_t = tanh(x_t*W_(xg)+h_(t-1)*W_(hg))</code>)</li>
  <li>삭제 게이트(망각 게이트) : 이전 시점의 입력을 얼마나 반영할 지를 결정, 기억을 삭제하기 위한 게이트로 0에 가까울 수록 많이 제거된 상태(<code class="language-plaintext highlighter-rouge">f_t = sigmoid(x_t*W_(xf) + h_(t-1)*W_(hf))</code>)</li>
  <li>출력 게이트 : 현재 시점의 x값과 이전 시점의 은닉 상태가 시그모이드 함수를 지난 값으로 현재 시점의 은닉 상태를 결정(<code class="language-plaintext highlighter-rouge">o_t = sigmoid(x_t*W_(xo)+h_(t-1)*W_(ho)), h_t = o_tㅇtanh(c_t)</code>)</li>
</ul>

<h3 id="gated-recurrent-unit-gru"><span class="me-2">Gated Recurrent Unit; GRU</span><a href="#gated-recurrent-unit-gru" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li>GRU : LSTM에서 3개의 게이트(출력, 입력, 삭제)를 사용했던 반면, GRU에서는 업데이트 게이트, 리셋 게이트 2개를 사용하여 LSTM의 구조를 간략화</li>
</ul>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/nlp/GRU.jpg" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

<h3 id="rnn-language-model"><span class="me-2">RNN Language Model</span><a href="#rnn-language-model" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li>Teacher Forcing(교사 강요) : 테스트 과정에서 t시점의 출력값이 t+1시점의 입력값으로 들어가도록 하는 RNN model에서, 훈련 과정 중에는 입력에 대한 예측값을 입력으로 하지 않고, 이미 정답을 알고 있는 레이블을 기반으로 훈련하여 훈련 과정을 단축하는 기법, 활성화 함수로는 softmax, 손실 함수로는 cross entropy를 사용</li>
  <li>Input layer : 특정 시점에서의 입력 단어에 대한 one-hot vector로 입력 받아 입력층의 가중치 행렬을 거쳐 embedding vector를 출력, NNLM과의 차이로는 window로 입력받아 한번에 처리된 lookup table과는 달리, 단어 입력 시점에 따라 입력층의 가중칠 행렬의 변화가 발생하기에 같은 단어에 대한 embedding vector 값이 다를 수 있음</li>
  <li>Embedding layer(linear) : Projection layer(투사층)의 역할로, 결과로 얻는 벡터를 Embedding vector 라고 함.</li>
  <li>Hidden layer(non-linear) : 이전 시점의 hidden state를 가중치와 편향을 사용한 선형 결합된 값을 출력하고 이를 활성화 함수(hyperbolic tansent)를 거쳐 현 시점의 hidden state를 생성, 다음 시점의 은닉층의 연산에 사용하거나 출력층으로 전달</li>
  <li>Output layer : 전달 받은 은닉 상태와 출력층의 가중치를 사용하여 이를 활성화 함수; softmax를 거쳐 각 원소의 값을 0~1 사이의 실수값을 가지며 총 합은 1이 되는 상태로 변환, 실제값에 해당하는 값과 cross-entropy 손실함수를 사용하여 역전파 실시</li>
</ul>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><span class="c1"># Preprocessing
</span><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">tensorflow.keras.preprocessing.text</span> <span class="kn">import</span> <span class="n">Tokenizer</span>
<span class="kn">from</span> <span class="n">tensorflow.keras.preprocessing.sequence</span> <span class="kn">import</span> <span class="n">pad_sequences</span>
<span class="kn">from</span> <span class="n">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>

<span class="n">text</span> <span class="o">=</span> <span class="sh">"""</span><span class="s">경마장에 있는 말이 뛰고 있다</span><span class="se">\n</span><span class="s">
그의 말이 법이다</span><span class="se">\n</span><span class="s">
가는 말이 고와야 오는 말이 곱다</span><span class="se">\n</span><span class="sh">"""</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="nc">Tokenizer</span><span class="p">()</span>
<span class="n">tokenizer</span><span class="p">.</span><span class="nf">fit_on_texts</span><span class="p">([</span><span class="n">text</span><span class="p">])</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">word_index</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Vocabulary size : %d</span><span class="sh">"</span> <span class="o">%</span><span class="n">vocab_size</span><span class="p">)</span> <span class="c1"># Vocabulary size : 12
</span>
<span class="n">sequences</span> <span class="o">=</span> <span class="nf">list</span><span class="p">()</span>
<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">text</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="se">\n</span><span class="sh">'</span><span class="p">):</span> <span class="c1"># \n을 기준으로 문장 토큰화
</span>    <span class="n">encoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="nf">texts_to_sequences</span><span class="p">([</span><span class="n">line</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">encoded</span><span class="p">)):</span>
        <span class="n">sequence</span> <span class="o">=</span> <span class="n">encoded</span><span class="p">[:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">sequences</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Number of samples for training : %d</span><span class="sh">"</span> <span class="o">%</span><span class="nf">len</span><span class="p">(</span><span class="n">sequences</span><span class="p">))</span> <span class="c1"># Number of samples for training : 11
</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sequences</span><span class="p">)</span> <span class="c1"># 모든 샘플에서 길이가 가장 긴 샘플의 길이
</span>
<span class="n">sequences</span> <span class="o">=</span> <span class="nf">pad_sequences</span><span class="p">(</span><span class="n">sequences</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="sh">'</span><span class="s">pre</span><span class="sh">'</span><span class="p">)</span> <span class="c1"># label로 사용될 단어들의 길이를 padding을 통해 일치
</span>
<span class="c1"># label 분리
</span><span class="n">sequences</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">sequences</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">sequences</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">sequences</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">y</span> <span class="o">=</span> <span class="nf">to_categorical</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">)</span>
</code></div></div>

<hr />

<h3 id="word-embedding"><span class="me-2">Word Embedding</span><a href="#word-embedding" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li>자연어 처리의 성능에 크게 영향을 미치는 단어(텍스트)를 숫자로 변환하는 과정;벡터화에서 인공 신경망 학습을 통해 단어를 밀집 표현으로 변환하는 방법</li>
  <li>단어를 밀집 벡터의 형태로 표현하는 방법</li>
</ul>

<h3 id="sparse-representation희소-표현"><span class="me-2">Sparse Representation(희소 표현)</span><a href="#sparse-representation희소-표현" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li>one-hot-encoding과 같이 대부분의 값이 0으로 표현되는 방법으로 단어의 개수가 늘어나면서 벡터의 차원이 지나치게 커져 공간적 낭비를 일으킴</li>
  <li>벡터간의 유의미한 유사성을 표현할 수 없기에, Disributed representation(분산 표현)을 사용해 다차원 공간에 단어의 의미를 벡터화하여 유사성을 벡터화하는 embedding을 사용
    <ul>
      <li>분산 표현 : 비슷한 문맥에서 등장하는 단어들은 비슷한 의미를 가진다는 가정(분포 가설) 하에 주로 함께 등장하는 단어들의 벡터들에 대해 학습하고 의미를 저차원에 벡터의 여러 차원에 분산하여 표현</li>
    </ul>
  </li>
</ul>

<h3 id="dense-representation밀집-표현"><span class="me-2">Dense Representation(밀집 표현)</span><a href="#dense-representation밀집-표현" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li>벡터의 차원을 단어 집합의 크기로 상정하지 않고 사용자가 설정한 값으로 모든 단어의 벡터 표현의 차원을 지정하여 실수값으로 표현</li>
</ul>

<h3 id="word2vecword-to-vector"><span class="me-2">Word2Vec(Word to Vector)</span><a href="#word2vecword-to-vector" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li>원-핫 벡터와는 달리 단어 벡터 간의 유사도를 반영하여 단어를 수치화하는 방법</li>
  <li>다음 단어를 예측하는 NNLM과 달리 Word2Vec은 워드 임베딩을 목적으로 중심 단어를 예측하여 학습하므로 예측 전, 후의 단어들을 모두 참고</li>
  <li>은닉층을 제거하여 투사층 다음에 바로 출력층으로 연결하기에 연산량이 줄어 학습속도의 이점
    <ul>
      <li>Hierarchical softmax(계층적 소프트맥스)</li>
      <li>Negative sampling</li>
    </ul>
  </li>
  <li>CBOW(Continuous Bag of Words) : 주변에 있는 단어들을 입력으로 투사층에서 입력 단어 벡터들의 lookup table 평균(input vector * <code class="language-plaintext highlighter-rouge">W</code>)과 출력층에서의 <code class="language-plaintext highlighter-rouge">W'</code>을 통해 중간에 있는 단어를 예측
    <ul>
      <li>Center word : 예측해야 할 단어</li>
      <li>Context word : 예측에 사용되는 단어</li>
      <li>Window : 중심 단어를 예측하기 위해서 참고할 단어의 범위로 window=n일 때, center word를 중심으로 앞 뒤의 n개, 총 2n개의 단어를 참고</li>
      <li>Sliding window : 윈도우를 옆으로 움직여서 주변 단어와 중심 단어의 선택을 변경해가면서 학습을 위한 데이터 셋을 만드는 방법</li>
    </ul>
  </li>
  <li>Skip-Gram : 중간에 있는 단어를 입력으로 주변 단어 <code class="language-plaintext highlighter-rouge">2n</code>개를 예측</li>
</ul>

<h3 id="fasttext"><span class="me-2">FastText</span><a href="#fasttext" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li>단어 안에도 여러 단어들이 존재하는 것으로 간주</li>
  <li>Subword를 고려하여 학습; 단어를 N-gram의 구성으로 취급하여 내부단어 토큰을 벡터화</li>
  <li>Dataset 내부의 모든 단어의 n-gram이 실시되기에, dataset 양이 충분할 경우 Out Of Vocabulary(OOV)에 대해서도 다른 단어와의 유사도를 계산 가능</li>
  <li>등장 빈도 수가 적은 단어(rare words)에 대해 비교적 높은 임베딩 벡터값을 얻음</li>
  <li>노이즈가 많은 코퍼스에서 강점을 가짐; 훈련 코퍼스에 오타나 맞춤법이 틀린 단어가 있을 경우의 임베딩 가능</li>
</ul>

<div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><span class="kn">from</span> <span class="n">gensim.models</span> <span class="kn">import</span> <span class="n">FastText</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">FastText</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">sg</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">model</span><span class="p">.</span><span class="n">wv</span><span class="p">.</span><span class="nf">most_similar</span><span class="p">(</span><span class="sh">"</span><span class="s">electrofishing</span><span class="sh">"</span><span class="p">)</span>
</code></div></div>

<div class="language-bash highlighter-rouge"><div class="code-header">
        <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><span class="o">[(</span><span class="s1">'electrolux'</span>, 0.7934642434120178<span class="o">)</span>, <span class="o">(</span><span class="s1">'electrolyte'</span>, 0.78279709815979<span class="o">)</span>, <span class="o">(</span><span class="s1">'electro'</span>, 0.779127836227417<span class="o">)</span>, <span class="o">(</span><span class="s1">'electric'</span>, 0.7753111720085144<span class="o">)</span>, <span class="o">(</span><span class="s1">'airbus'</span>, 0.7648627758026123<span class="o">)</span>, <span class="o">(</span><span class="s1">'fukushima'</span>, 0.7612422704696655<span class="o">)</span>, <span class="o">(</span><span class="s1">'electrochemical'</span>, 0.7611693143844604<span class="o">)</span>, <span class="o">(</span><span class="s1">'gastric'</span>, 0.7483425140380859<span class="o">)</span>, <span class="o">(</span><span class="s1">'electroshock'</span>, 0.7477173805236816<span class="o">)</span>, <span class="o">(</span><span class="s1">'overfishing'</span>, 0.7435552477836609<span class="o">)]</span>
</code></div></div>

<ul>
  <li>한국어에서의 FastText
    <ul>
      <li>음절 단위</li>
      <li>자모 단위(초성, 중성, 종성)</li>
    </ul>
  </li>
</ul>

<h3 id="pre-trained-word-embedding"><span class="me-2">Pre-trained Word Embedding</span><a href="#pre-trained-word-embedding" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li>Keras에서의 Embedding() : 인공 신경망 구조 관점에서 embedding layer를 제공
    <ul>
      <li>Embedding Layer는 look-up table(=weight matrix) : 입력 시퀀스의 각 단어들은 모두 정수 인코딩(index)되어 임베딩 층을 거쳐 밀집 벡터(dense vector=embedding vector)로 mapping, 밀집 벡터는 인공 신경망의 학습 과정에서 가중치가 학습되는 것과 같은 방식(역전파)으로 훈련</li>
      <li>Embedding layer 사용</li>
    </ul>

    <div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code>  <span class="c1"># Preprocessing
</span>  <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
  <span class="kn">from</span> <span class="n">tensorflow.keras.preprocessing.text</span> <span class="kn">import</span> <span class="n">Tokenizer</span>
  <span class="kn">from</span> <span class="n">tensorflow.keras.preprocessing.sequence</span> <span class="kn">import</span> <span class="n">pad_sequences</span>

  <span class="n">sentences</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">nice great best amazing</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">stop lies</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">pitiful nerd</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">excellent work</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">supreme quality</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">bad</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">highly respectable</span><span class="sh">'</span><span class="p">]</span>
  <span class="n">y_train</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>

  <span class="n">tokenizer</span> <span class="o">=</span> <span class="nc">Tokenizer</span><span class="p">()</span>
  <span class="n">tokenizer</span><span class="p">.</span><span class="nf">fit_on_texts</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>
  <span class="n">vocab_size</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">word_index</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

  <span class="n">X_encoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="nf">texts_to_sequences</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>
  <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Encoding to integer : </span><span class="sh">'</span><span class="p">,</span> <span class="n">X_encoded</span><span class="p">)</span>
  <span class="c1"># 정수 인코딩 결과 : [[1, 2, 3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13], [14, 15]]
</span>
  <span class="n">max_len</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">l</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">X_encoded</span><span class="p">)</span> <span class="c1"># 샘플의 최대 길이
</span>  <span class="n">X_train</span> <span class="o">=</span> <span class="nf">pad_sequences</span><span class="p">(</span><span class="n">X_encoded</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="sh">'</span><span class="s">post</span><span class="sh">'</span><span class="p">)</span> <span class="c1"># post(뒤)에 패딩
</span>  <span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
</code></div>    </div>

    <div class="language-bash highlighter-rouge"><div class="code-header">
        <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code>  패딩 결과 :
  <span class="o">[[</span> 1  2  3  4]
  <span class="o">[</span> 5  6  0  0]
  <span class="o">[</span> 7  8  0  0]
  <span class="o">[</span> 9 10  0  0]
  <span class="o">[</span>11 12  0  0]
  <span class="o">[</span>13  0  0  0]
  <span class="o">[</span>14 15  0  0]]
</code></div>    </div>

    <div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code>  <span class="c1"># Binary Classification Model
</span>  <span class="kn">from</span> <span class="n">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
  <span class="kn">from</span> <span class="n">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Embedding</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Flatten</span>

  <span class="n">embedding_dim</span> <span class="o">=</span> <span class="mi">4</span>
    
  <span class="n">model</span> <span class="o">=</span> <span class="nc">Sequential</span><span class="p">()</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">,</span> <span class="n">input_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Flatten</span><span class="p">())</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">sigmoid</span><span class="sh">'</span><span class="p">))</span>

  <span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="sh">'</span><span class="s">adam</span><span class="sh">'</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="sh">'</span><span class="s">binary_crossentropy</span><span class="sh">'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">acc</span><span class="sh">'</span><span class="p">])</span>
  <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></div>    </div>
  </li>
  <li>Pre-trained word embbedding
    <ul>
      <li>GloVe</li>
      <li>Word2Vec</li>
    </ul>
  </li>
</ul>

<h3 id="embeddings-from-language-modelelmo"><span class="me-2">Embeddings from Language Model;ELMo</span><a href="#embeddings-from-language-modelelmo" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li>언어 모델로 하는 임베딩으로 사전 훈련된 언어 모델을 활용</li>
  <li>완전히 다른 의미를 갖는 같은 단어에 대해 기존의 모델들의 임베딩 벡터들은 제대로 반영 불가</li>
  <li>같은 표기의 단어라도 문맥에 따라서 다르게 워드 임베딩을 할 수 있음(Contextualized Word Embedding)</li>
</ul>

<h3 id="bidirectional-language-modelbilm"><span class="me-2">Bidirectional Language Model;biLM</span><a href="#bidirectional-language-modelbilm" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li>은닉층이 최소 2개 이상의 다층 구조를 가지며 토큰화된 문장으로 CNN을 이용한 문자 임베딩을 통해 얻은 단어 벡터를 입력, 순방향과 역방향의 언어모델을 사용</li>
</ul>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/nlp/biLM.png" class="img-fluid rounded z-depth-1" zoomable=true %}
    </div>
</div>

<ol>
  <li>각 층의 출력값을 concatenate</li>
  <li>각 층의 출력값 별로 가중치 부여</li>
  <li>각 층의 출력값의 합을 출력</li>
  <li>벡터의 크기를 결정하는 스칼라 매개 변수를 곱하여 ELMo representation을 도출
    <ul>
      <li>양방향 RNN에서는 순방향의 Hidden State과 역방향의 Hidden State을 concatenate하여 다음층의 입력으로 사용하고, biLM은 각각을 별개의 모델로 학습</li>
    </ul>
  </li>
</ol>

<h3 id="bio-representation"><span class="me-2">BIO Representation</span><a href="#bio-representation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li>Named Entity Recognition(개체명 인식) : chatBoT 등에서 필요한 주요 전처리 작업으로, 직접 목적에 맞는 데이터를 준비하여 모델을 생성하는 것이 도메인 또는 목적에 특화한 성능을 보임</li>
  <li>BIO Tagging : 개체명 인식에서 corpus로부터 개체명을 인식하기 위한 방법 중 하나로, 여러 종류의 개체에 대해 어떤 종류에 속하는 지도 함께 태깅(B:Begin=개체명이 시작되는 부분, I:Inside=개체명의 내부 부분, O:Outside=개체명이 아닌 부분)</li>
</ul>

  </div>

  <div class="post-tail-wrapper text-muted">
    <!-- categories -->
    
      <div class="post-meta mb-3">
        <i class="far fa-folder-open fa-fw me-1"></i>
        
          <a href="/categories/nlp/">NLP</a>
      </div>
    

    <!-- tags -->
    
      <div class="post-tags">
        <i class="fa fa-tags fa-fw me-1"></i>
        
          <a
            href="/tags/concept/"
            class="post-tag no-text-decoration"
          >Concept</a>
        
      </div>
    

    <div
      class="
        post-tail-bottom
        d-flex justify-content-between align-items-center mt-5 pb-2
      "
    >
      <div class="license-wrapper">
        
          

          This post is licensed under 
        <a href="https://creativecommons.org/licenses/by/4.0/">
          CC BY 4.0
        </a>
         by the author.
        
      </div>

      <!-- Post sharing snippet -->

<div class="share-wrapper d-flex align-items-center">
  <span class="share-label text-muted">Share</span>
  <span class="share-icons">
    
    
    

    

      

      <a href="https://twitter.com/intent/tweet?text=Long%20Short-Term%20Memory%20in%20RNN%20-%20Patrick's%20Dev.%20Blog&url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2FLSTM%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Twitter" aria-label="Twitter">
        <i class="fa-fw fa-brands fa-square-x-twitter"></i>
      </a>
    

      

      <a href="https://www.facebook.com/sharer/sharer.php?title=Long%20Short-Term%20Memory%20in%20RNN%20-%20Patrick's%20Dev.%20Blog&u=http%3A%2F%2Flocalhost%3A4000%2Fposts%2FLSTM%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Facebook" aria-label="Facebook">
        <i class="fa-fw fab fa-facebook-square"></i>
      </a>
    

      

      <a href="https://t.me/share/url?url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2FLSTM%2F&text=Long%20Short-Term%20Memory%20in%20RNN%20-%20Patrick's%20Dev.%20Blog" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Telegram" aria-label="Telegram">
        <i class="fa-fw fab fa-telegram"></i>
      </a>
    

    <button
      id="copy-link"
      aria-label="Copy link"
      class="btn small"
      data-bs-toggle="tooltip"
      data-bs-placement="top"
      title="Copy link"
      data-title-succeed="Link copied successfully!"
    >
      <i class="fa-fw fas fa-link pe-none fs-6"></i>
    </button>
  </span>
</div>

    </div>
    <!-- .post-tail-bottom -->
  </div>
  <!-- div.post-tail-wrapper -->
</article>


            
          </main>

          <!-- panel -->
          <aside aria-label="Panel" id="panel-wrapper" class="col-xl-3 ps-2 text-muted">
            <div class="access">
              <!-- Get 5 last posted/updated posts -->














  <section id="access-lastmod">
    <h2 class="panel-heading">Recently Updated</h2>
    <ul class="content list-unstyled ps-0 pb-1 ms-1 mt-2">
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/Graph/">Graph</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/pip_requiremntes/">Pip_requiremntes</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/BPE/">Bpe</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/Huggingface/">Huggingface</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/Datasets/">Datasets</a>
        </li>
      
    </ul>
  </section>
  <!-- #access-lastmod -->


              <!-- The trending tags list -->















  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        



  <section>
    <h2 class="panel-heading">Trending Tags</h2>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/concept/">Concept</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/grammer/">Grammer</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/bfs/">BFS</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/dfs/">DFS</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/graph/">Graph</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/paper/">Paper</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/tutorial/">Tutorial</a>
      
    </div>
  </section>


            </div>

            
              
              






  <div class="toc-border-cover z-3"></div>
  <section id="toc-wrapper" class="invisible position-sticky ps-0 pe-4 pb-4">
    <h2 class="panel-heading ps-3 pb-2 mb-0">Contents</h2>
    <nav id="toc"></nav>
  </section>


            
          </aside>
        </div>

        <div class="row">
          <!-- tail -->
          <div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-md-4">
            
              
              <!-- Recommend the other 3 posts according to the tags and categories of the current post. -->

<!-- The total size of related posts -->


<!-- An random integer that bigger than 0 -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy} -->















  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  
    
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  











  <aside id="related-posts" aria-labelledby="related-label">
    <h3 class="mb-4" id="related-label">Further Reading</h3>
    <nav class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4">
      
        <article class="col">
          <a href="/posts/Attention_Machanism/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1701774720"
  data-df="ll"
  
>
  Dec  5, 2023
</time>

              <h4 class="pt-0 my-2">Attention Algorithm</h4>
              <div class="text-muted">
                <p>Seq2seq based on RNN seq2seq Model : RNN에 기반하여 Encoder에서 입력 시퀀스를 context vector라는 하나의 고정된 크기의 벡터 표현으로 압축하고, Decoder에서 출력 시퀀스를 생성 문제점    하나의 고정된 크기의 벡터에 모든 정보를 압축; 정보 손실이 발생   RNN의 문제점 중 하나인 Vanishi...</p>
              </div>
            </div>
          </a>
        </article>
      
        <article class="col">
          <a href="/posts/Subword_Tokenizer/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1701168600"
  data-df="ll"
  
>
  Nov 28, 2023
</time>

              <h4 class="pt-0 my-2">Subword Tokenizer</h4>
              <div class="text-muted">
                <p>Subword Tokenizer Subword    OOV(Out-Of Vocabulary) : 새로 제시된 단어에 대해 기존의 dictionary 내의 단어가 아닌 경우   Subword : 하나의 단어를 구성하는 더 작은 단위의 의미를 가진 어구   Subword segmenation : 하나의 단어를 여러 서브 워드로 분리해서 단어를 인코딩 및 ...</p>
              </div>
            </div>
          </a>
        </article>
      
        <article class="col">
          <a href="/posts/Seq2seq/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1699942320"
  data-df="ll"
  
>
  Nov 14, 2023
</time>

              <h4 class="pt-0 my-2">Sequence-to-sequence Algorithm with RNN</h4>
              <div class="text-muted">
                <p>Sequence-to-Sequence; Seq2seq Seq2seq    입력된 Sequence로부터 다른 도메인의 Sequence를 출력하는 모델(ex - chatBoT, 기계 번역, STT, 내용 요약)   RNN을 조립하는 방식(하나의 RNN을 Encoder, 다른 하나를 Decoder로 구현하여 이를 연결)에 따라 구조를 생성   Encoder...</p>
              </div>
            </div>
          </a>
        </article>
      
    </nav>
  </aside>
  <!-- #related-posts -->


            
              
              <!-- Navigation buttons at the bottom of the post. -->

<nav class="post-navigation d-flex justify-content-between" aria-label="Post Navigation">
  
  

  
    <a
      href="/posts/Seq2seq/"
      class="btn btn-outline-primary"
      aria-label="Older"
    >
      <p>Sequence-to-sequence Algorithm with RNN</p>
    </a>
  

  
    <a
      href="/posts/Subword_Tokenizer/"
      class="btn btn-outline-primary"
      aria-label="Newer"
    >
      <p>Subword Tokenizer</p>
    </a>
  
</nav>

            

            <!-- The Footer -->

<footer
  aria-label="Site Info"
  class="
    d-flex flex-column justify-content-center text-muted
    flex-lg-row justify-content-lg-between align-items-lg-center pb-lg-3
  "
>
  <p>©
    <time>2025</time>

    
      <a href="https://twitter.com/username">Patrick</a>.
    

    
      <span
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author."
      >Some rights reserved.</span>
    
  </p>

  <p>Using the <a
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="v7.2.4"
        href="https://github.com/cotes2020/jekyll-theme-chirpy"
        target="_blank"
        rel="noopener"
      >Chirpy</a> theme for <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>.
  </p>
</footer>

          </div>
        </div>

        <!-- The Search results -->

<div id="search-result-wrapper" class="d-flex justify-content-center d-none">
  <div class="col-11 content">
    <div id="search-hints">
      <!-- The trending tags list -->















  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        



  <section>
    <h2 class="panel-heading">Trending Tags</h2>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/concept/">Concept</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/grammer/">Grammer</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/bfs/">BFS</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/dfs/">DFS</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/graph/">Graph</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/paper/">Paper</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/tutorial/">Tutorial</a>
      
    </div>
  </section>


    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>

      </div>

      <aside aria-label="Scroll to Top">
        <button id="back-to-top" type="button" class="btn btn-lg btn-box-shadow">
          <i class="fas fa-angle-up"></i>
        </button>
      </aside>
    </div>

    <div id="mask" class="d-none position-fixed w-100 h-100 z-1"></div>

    
      <aside
  id="notification"
  class="toast"
  role="alert"
  aria-live="assertive"
  aria-atomic="true"
  data-bs-animation="true"
  data-bs-autohide="false"
>
  <div class="toast-header">
    <button
      type="button"
      class="btn-close ms-auto"
      data-bs-dismiss="toast"
      aria-label="Close"
    ></button>
  </div>
  <div class="toast-body text-center pt-0">
    <p class="px-2 mb-3">A new version of content is available.</p>
    <button type="button" class="btn btn-primary" aria-label="Update">
      Update
    </button>
  </div>
</aside>

    

    <!-- Embedded scripts -->

    
      
      <!-- The comments switcher -->


    

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script>
  
  document.addEventListener('DOMContentLoaded', () => {
    SimpleJekyllSearch({
      searchInput: document.getElementById('search-input'),
      resultsContainer: document.getElementById('search-results'),
      json: '/assets/js/data/search.json',
      searchResultTemplate: '  <article class="px-1 px-sm-2 px-lg-4 px-xl-0">    <header>      <h2><a href="{url}">{title}</a></h2>      <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">        {categories}        {tags}      </div>    </header>    <p>{content}</p>  </article>',
      noResultsText: '<p class="mt-5">Oops! No results found.</p>',
      templateMiddleware: function(prop, value, template) {
        if (prop === 'categories') {
          if (value === '') {
            return `${value}`;
          } else {
            return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
          }
        }

        if (prop === 'tags') {
          if (value === '') {
            return `${value}`;
          } else {
            return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
          }
        }
      }
    });
  });
</script>

  </body>
</html>

